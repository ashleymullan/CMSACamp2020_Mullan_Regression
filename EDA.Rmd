---
title: "R Notebook with EDA and Beginnings of Model"
output: html_notebook
---


general comments:
1. Ashley needs to master GitHub
2. our EDA led us to make a bunch of new variables averaging the season counts per game to somewhat standardize them
3. we are considering these averaged variables and the percentage variables
4. our two designated candidate response variables are average points per game and average score differential
5. we wanted to use lasso regression as a kind of confidence booster with our variable selection, we need a little help interpreting them and would also like to make the graphs with the coefficients as a function of lambda but were a little stuck since they were loaded into the lecture slides as images
6. each variable I looked at appeared roughly unimodal but we had some tail concerns, which motivated us to look at outliers (there were none)
7. context question: why do we have 36 teams coded in but only 30 observations in each season?
8. we plan to cross validate by season. we dedicated 3 code blocks to setting this up.

```{r}
library(GGally)
library(ggcorrplot)
library(tidyverse)
library(glmnet)
library(broom)
library(coefplot)
```

```{r}
data <- read.csv("http://www.stat.cmu.edu/cmsac/sure/materials/data/regression_projects/nba_team_season_summary.csv")
head(data)
head(data_copy_for_adding_fold_id)
data <- data %>% mutate(games = wins + losses, appg = total_points/games, asd = score_differential/games) %>% arrange(appg)
data %>% ggplot(aes(x = appg)) + geom_histogram(bins = 24) + geom_freqpoly(color = "pink")

#checking for unique observations
unique(data$season)  #we have every season from 2003-04 to 2018-19
unique(data$team) #we have 36 teams
```
Comments:
  * most seasons have 82 games, 30 have 66, 2 have 81. why?
  * appg is average points per game
  * appg appears almost normal but with a bit of a right tail, we checked outliers via intro to stat method,     115 ish was the cutoff, it's higher than where we start to see problems
  * we later split our data by season, which gave us datasets of size 29-30. but we have 36 unique teams. interesting.
  * each observation is the stats for a team for an individual season
  * we originally had 479 observations of 28 variables, mutated up to 30


```{r}
#assumption check  (to see if distributions look close to normal)
assumptionChecker <- function(info, var) {
  info %>% ggplot(aes(x = var)) + geom_histogram()
}

assumptionChecker(data, data$field_goal_perc)
assumptionChecker(data, data$three_point_perc)
assumptionChecker(data, data$free_throw_perc)
assumptionChecker(data, data$two_point_perc)
assumptionChecker(data, data$win_perc)
assumptionChecker(data, data$asd)

assumptionChecker(data_copy_for_adding_fold_id, data_copy_for_adding_fold_id$avg_rebounds)
assumptionChecker(data_copy_for_adding_fold_id, data_copy_for_adding_fold_id$avg_assists)
assumptionChecker(data_copy_for_adding_fold_id, data_copy_for_adding_fold_id$avg_steals)
assumptionChecker(data_copy_for_adding_fold_id, data_copy_for_adding_fold_id$avg_blocks)
assumptionChecker(data_copy_for_adding_fold_id, data_copy_for_adding_fold_id$avg_blocks_against)
assumptionChecker(data_copy_for_adding_fold_id, data_copy_for_adding_fold_id$avg_fouls)
assumptionChecker(data_copy_for_adding_fold_id, data_copy_for_adding_fold_id$avg_turnovers)


```

```{r}
#moral of the story: we have no outliers by definition of outside plus/minus 1.5 * IQR
summary(data$field_goal_perc)
iqrScaledFGP <- 1.5 * (.4640-.4440)
removedOutliersFGP <- data %>% filter((field_goal_perc >= .4440 - iqrScaledFGP) && (field_goal_perc <= .4640 + iqrScaledFGP))

summary(data$three_point_perc)
iqrScaled3PP <- 1.5 * (.3674-.3440)
removedOutliers3PP <- data %>% filter((three_point_perc >= .3440 - iqrScaled3PP) && (three_point_perc <= .3674 + iqrScaled3PP))

summary(data$free_throw_perc)
iqrScaledFTP <- 1.5 * (.7790-.7415)
removedOutliersFTP <- data %>% filter((free_throw_perc >= .7415 - iqrScaledFTP) && (free_throw_perc <= .7790 + iqrScaledFTP))

summary(data$two_point_perc)
iqrScaled2PP <- 1.5 * (.5032-.4723)
removedOutliers2PP <- data %>% filter((two_point_perc >= .4723 - iqrScaled2PP) && (two_point_perc <= .5032 + iqrScaled2PP))

summary(data$win_perc)
iqrScaledWP <- 1.5 * (.610-.390)
removedOutliersWP <- data %>% filter((win_perc >= .4440 - iqrScaledWP) && (win_perc <= .4640 + iqrScaledWP))

summary(data$asd)
iqrScaledASD <- 1.5 * (3.426829 + 3.030488)
removedOutliersASD <- data %>% filter((asd >= -3.030488 - iqrScaledASD) && (asd <= 3.426829 + iqrScaledASD))

summary(data_avg_only$avg_turnovers)
iqrScaledATO <- 1.5 * (15.10-13.72)
iqrScaledATO
removedOutliersATO <- data_avg_only %>% filter((avg_turnovers >= 13.72 - iqrScaledATO) && (avg_turnovers <= 15.10 + iqrScaledATO))

summary(data_avg_only$avg_fouls)
iqrScaledAF <- 1.5 * (22.04 - 19.68)
removedOutliersAF <- data_avg_only %>% filter((avg_fouls >= 19.68 - iqrScaledAF) && (avg_fouls <= 22.04 + iqrScaledAF))

summary(data_avg_only$avg_assists)
iqrScaledAA <- 1.5 * (23.09 - 20.46)
removedOutliersAA <- data_avg_only %>% filter((avg_assists >= 20.46 - iqrScaledAA) && (avg_fouls <= 23.09 + iqrScaledAA))

summary(data_avg_only$avg_rebounds)
iqrScaledAR <- 1.5 * (43.68-41.01)
removedOutliersAR <- data_avg_only %>% filter((avg_rebounds >= 41.01 - iqrScaledAR) && (avg_rebounds <= 43.68 + iqrScaledAR))

summary(data_avg_only$avg_steals)
iqrScaledAS <- 1.5 * (8.134-6.973)
removedOutliersAS <- data_avg_only %>% filter((avg_steals >= 6.973 - iqrScaledAS) && (avg_steals <= 8.134 + iqrScaledAS))

summary(data_avg_only$avg_blocks)
iqrScaledAB <- 1.5 * (5.378 - 4.280)
removedOutliersAB <- data_avg_only %>% filter((avg_blocks >= 4.280 - iqrScaledAB) && (avg_blocks <= 5.378 + iqrScaledAB))

summary(data_avg_only$avg_d_rebounds)
iqrScaledADR <- 1.5 * (32.90-29.87)
removedOutliersADR <- data_avg_only %>% filter((avg_d_rebounds >= 29.87 - iqrScaledADR) && (avg_d_rebounds <= 32.90 + iqrScaledADR))

summary(data_avg_only$avg_o_rebounds)
iqrScaledAOR <- 1.5 * (11.841-10.122)
removedOutliersAOR <- data_avg_only %>% filter((avg_o_rebounds >= 10.112 - iqrScaledAOR) && (avg_o_rebounds <= 11.841 + iqrScaledAOR))

blcoks agianst, 
```

```{r}
#selects the variables I was looking at, all of the percentages and the avg score differential
dataForGGPairs <- data %>% select(field_goal_perc, three_point_perc, free_throw_perc, two_point_perc, win_perc, asd)
ggpairs(data = dataForGGPairs)
```

```{r}
#This block initializes training sets that each leave out one season.
#each df includes all of the data except the one listed in the name
trainWO_2003_2004 <- data %>% filter(season != "2003-04")
trainWO_2004_2005 <- data %>% filter(season != "2004-05")
trainWO_2005_2006 <- data %>% filter(season != "2005-06")
trainWO_2006_2007 <- data %>% filter(season != "2006-07")
trainWO_2007_2008 <- data %>% filter(season != "2007-08")
trainWO_2008_2009 <- data %>% filter(season != "2008-09")
trainWO_2009_2010 <- data %>% filter(season != "2009-10")
trainWO_2010_2011 <- data %>% filter(season != "2010-11")
trainWO_2011_2012 <- data %>% filter(season != "2011-12")
trainWO_2012_2013 <- data %>% filter(season != "2012-13")
trainWO_2013_2014 <- data %>% filter(season != "2013-14")
trainWO_2014_2015 <- data %>% filter(season != "2014-15")
trainWO_2015_2016 <- data %>% filter(season != "2015-16")
trainWO_2016_2017 <- data %>% filter(season != "2016-17")
trainWO_2017_2018 <- data %>% filter(season != "2017-18")
trainWO_2018_2019 <- data %>% filter(season != "2018-19")
```

```{r}
#This block initializes test sets that each have one season.
#each df includes only the listed season
test_2003_2004 <- data %>% filter(season == "2003-04")
test_2004_2005 <- data %>% filter(season == "2004-05")
test_2005_2006 <- data %>% filter(season == "2005-06")
test_2006_2007 <- data %>% filter(season == "2006-07")
test_2007_2008 <- data %>% filter(season == "2007-08")
test_2008_2009 <- data %>% filter(season == "2008-09")
test_2009_2010 <- data %>% filter(season == "2009-10")
test_2010_2011 <- data %>% filter(season == "2010-11")
test_2011_2012 <- data %>% filter(season == "2011-12")
test_2012_2013 <- data %>% filter(season == "2012-13")
test_2013_2014 <- data %>% filter(season == "2013-14")
test_2014_2015 <- data %>% filter(season == "2014-15")
test_2015_2016 <- data %>% filter(season == "2015-16")
test_2016_2017 <- data %>% filter(season == "2016-17")
test_2017_2018 <- data %>% filter(season == "2017-18")
test_2018_2019 <- data %>% filter(season == "2018-19")
```

```{r}
#adds fold id
data_copy_for_adding_fold_id <- data_avg_only
data_copy_for_adding_fold_id <- data_copy_for_adding_fold_id %>%
  mutate(
    season = as.character(season),
    fold = case_when(
      season == '2003-04' ~ '1',
      season == '2004-05' ~ '2',
      season == '2005-06' ~ '3',
      season == '2006-07' ~ '4',
      season == '2007-08' ~ '5',
      season == '2008-09' ~ '6',
      season == '2009-10' ~ '7',
      season == '2010-11' ~ '8',
      season == '2011-12' ~ '9',
      season == '2012-13' ~ '10',
      season == '2013-14' ~ '11',
      season == '2014-15' ~ '12',
      season == '2015-16' ~ '13',
      season == '2016-17' ~ '14',
      season == '2017-18' ~ '15',
      season == '2018-19' ~ '16',
      TRUE ~ season
    )
  )
```

```{r}
with_averages_data <- data %>%
  mutate(games = wins + losses, 
         avg_points = total_points/games, 
         avg_turnovers= turnovers/games, 
         avg_fouls= personal_fouls/games, 
         avg_assists = assists/games, 
         avg_rebounds = total_rebounds/games, 
         avg_score_differential = score_differential/games, 
         avg_steals = steals/games, 
         avg_o_rebounds = offensive_rebounds/games,
         avg_d_rebounds = defensive_rebounds/games,
         avg_blocks = blocks/games,
         avg_blocks_against = blocks_against/games)
  
#has only averages and percents for doing our regression
data_avg_only <- with_averages_data %>%
  select(avg_points, team, season, avg_turnovers, avg_fouls, avg_assists, avg_rebounds, avg_o_rebounds, avg_d_rebounds, avg_score_differential, avg_steals, avg_blocks, avg_blocks_against, win_perc, field_goal_perc, three_point_perc, free_throw_perc, two_point_perc)
head(data_avg_only)

#lasso regression with points
points_model_x <- model.matrix(avg_points ~ ., data_avg_only)[, -1]
points_model_y <- data_avg_only$avg_points
fit_lasso_points_cv <- cv.glmnet(points_model_x, points_model_y, foldid = as.double(data_copy_for_adding_fold_id$fold), alpha = 1)
fit_lasso_points_cv$lambda.min
plot(fit_lasso_points_cv)
#why is this exponential with so little error, does this mean something?

#lasso regression with score differential
differential_model_x <- model.matrix(avg_score_differential ~ ., data_avg_only)[, -8]
differential_model_y <- data_avg_only$avg_score_differential
fit_lasso_differential_cv <- cv.glmnet(differential_model_x, differential_model_y, foldid = as.double(data_copy_for_adding_fold_id$fold), alpha = 1)
fit_lasso_differential_cv$lambda.min
plot(fit_lasso_differential_cv)
plot(fit_lasso_differential_cv$glmnet.fit, "lambda", label = TRUE)
```

```{r}
#cross validation function that returns LM object
crossValidatorInator <- function(df, recipe, foldID) {
  df <- df %>% filter(fold != foldID)
  lm_object <- lm(data = df, formula = as.formula(recipe))
  return(lm_object)
}

#cross validation of null models for points
null_model_linear_fit_points <- rep(NULL, 16)
for (i in 1:16){
  null_model_linear_fit_points[[i]] <- crossValidatorInator(data_copy_for_adding_fold_id, avg_points ~ 1, i)
}

#cross validation of all var models for points and plots
all_vars_model_linear_fit_points <- rep(NULL, 16)
for (i in 1:16) {
  all_vars_model_linear_fit_points[[i]] <- crossValidatorInator(data_copy_for_adding_fold_id, avg_points ~ . - fold, i)
}

#cross validation of null models for asd
null_model_linear_fit_asd <- rep(NULL, 16)
for (i in 1:16){
  null_model_linear_fit_asd[[i]] <- crossValidatorInator(data_copy_for_adding_fold_id, avg_score_differential ~ 1, i)
}

#cross validation of all var models for asd
all_vars_model_linear_fit_asd <- rep(NULL, 16)
for (i in 1:16){
  all_vars_model_linear_fit_asd[[i]] <- crossValidatorInator(data_copy_for_adding_fold_id, avg_score_differential ~ . - fold, i)
}

#cross val of lesser known avg frequencies for points (modelA)  we liked it
crossValidatorInator_temp(data_copy_for_adding_fold_id, avg_points ~ avg_turnovers + avg_fouls + avg_assists + avg_rebounds + avg_steals + avg_blocks + avg_blocks_against, 16)

lesser_known_model_linear_fit_points <- rep(NULL, 16)
for (i in 1:16){
  lesser_known_model_linear_fit_points[[i]] <- crossValidatorInator(data_copy_for_adding_fold_id, avg_points ~ avg_turnovers + avg_fouls + avg_assists + avg_rebounds + avg_steals + avg_blocks + avg_blocks_against, i)
}
#for(i in 1:16) {plot(lesser_known_model_linear_fit_points[[i]])}
coefficient_frame_lesser_known_points <- data.frame(lesser_known_model_linear_fit_points[[1]]$coefficients, lesser_known_model_linear_fit_points[[2]]$coefficients, lesser_known_model_linear_fit_points[[3]]$coefficients, lesser_known_model_linear_fit_points[[4]]$coefficients, lesser_known_model_linear_fit_points[[5]]$coefficients, lesser_known_model_linear_fit_points[[6]]$coefficients, lesser_known_model_linear_fit_points[[7]]$coefficients, lesser_known_model_linear_fit_points[[8]]$coefficients, lesser_known_model_linear_fit_points[[9]]$coefficients, lesser_known_model_linear_fit_points[[10]]$coefficients, lesser_known_model_linear_fit_points[[11]]$coefficients, lesser_known_model_linear_fit_points[[12]]$coefficients, lesser_known_model_linear_fit_points[[13]]$coefficients, lesser_known_model_linear_fit_points[[14]]$coefficients, lesser_known_model_linear_fit_points[[15]]$coefficients, lesser_known_model_linear_fit_points[[16]]$coefficients)
transposeA <- as.data.frame(t(coefficient_frame_lesser_known_points))
interceptMeanA <- mean(transposeA$`(Intercept)`)
turnoverMeanA <- mean(transposeA$avg_turnovers)
foulsMeanA <- mean(transposeA$avg_fouls)
assistsMeanA <- mean(transposeA$avg_assists)
reboundsMeanA <- mean(transposeA$avg_rebounds)
stealsMeanA <- mean(transposeA$avg_steals)
blocksMeanA <- mean(transposeA$avg_blocks)
blocksAgainstMeanA <- mean(transposeA$avg_blocks_against)
testframeA <- data_copy_for_adding_fold_id 
testframeA %>% mutate(guess = (turnoverMeanA * avg_turnovers) + (foulsMeanA * avg_fouls) + (assistsMeanA * avg_assists) + (reboundsMeanA * avg_rebounds) + (stealsMeanA * avg_steals) + (blocksMeanA * avg_blocks) + (blocksAgainstMeanA * avg_blocks_against) + interceptMeanA, diff = guess - avg_points) %>% ggplot(aes(x = diff)) + geom_histogram()

#cross val of lesser known avg frequencies for asd (modelB) rejected, residuals center was off
crossValidatorInator_temp(data_copy_for_adding_fold_id, avg_score_differential ~ avg_turnovers + avg_fouls + avg_assists + avg_rebounds + avg_steals + avg_blocks + avg_blocks_against, 16)

lesser_known_model_linear_fit_asd <- rep(NULL, 16)
for (i in 1:16){
  lesser_known_model_linear_fit_asd[[i]] <- crossValidatorInator(data_copy_for_adding_fold_id, avg_score_differential ~ avg_turnovers + avg_fouls + avg_assists + avg_rebounds + avg_steals + avg_blocks + avg_blocks_against, i)
}
coefficient_frame_lesser_known_asd <- data.frame(lesser_known_model_linear_fit_asd[[1]]$coefficients, lesser_known_model_linear_fit_asd[[2]]$coefficients, lesser_known_model_linear_fit_asd[[3]]$coefficients, lesser_known_model_linear_fit_asd[[4]]$coefficients, lesser_known_model_linear_fit_points[[5]]$coefficients, lesser_known_model_linear_fit_asd[[6]]$coefficients, lesser_known_model_linear_fit_asd[[7]]$coefficients, lesser_known_model_linear_fit_asd[[8]]$coefficients, lesser_known_model_linear_fit_asd[[9]]$coefficients, lesser_known_model_linear_fit_asd[[10]]$coefficients, lesser_known_model_linear_fit_asd[[11]]$coefficients, lesser_known_model_linear_fit_asd[[12]]$coefficients, lesser_known_model_linear_fit_asd[[13]]$coefficients, lesser_known_model_linear_fit_asd[[14]]$coefficients, lesser_known_model_linear_fit_asd[[15]]$coefficients, lesser_known_model_linear_fit_asd[[16]]$coefficients)
transposeB <- as.data.frame(t(coefficient_frame_lesser_known_asd))
interceptMeanB <- mean(transposeB$`(Intercept)`)
turnoverMeanB <- mean(transposeB$avg_turnovers)
foulsMeanB <- mean(transposeB$avg_fouls)
assistsMeanB <- mean(transposeB$avg_assists)
reboundsMeanB <- mean(transposeB$avg_rebounds)
stealsMeanB <- mean(transposeB$avg_steals)
blocksMeanB <- mean(transposeB$avg_blocks)
blocksAgainstMeanB <- mean(transposeB$avg_blocks_against)
testframeB <- data_copy_for_adding_fold_id 
testframeB %>% mutate(guess = (turnoverMeanB * avg_turnovers) + (foulsMeanB * avg_fouls) + (assistsMeanB * avg_assists) + (reboundsMeanB * avg_rebounds) + (stealsMeanB * avg_steals) + (blocksMeanB * avg_blocks) + (blocksAgainstMeanB * avg_blocks_against) + interceptMeanB, diff = guess - avg_score_differential) %>% ggplot(aes(x = diff)) + geom_histogram()

#cross val of percentage stats for points
percentage_stats_model_linear_fit_points <- rep(NULL, 16)
for (i in 1:16){
  percentage_stats_model_linear_fit_points[[i]] <- crossValidatorInator(data_copy_for_adding_fold_id, avg_points ~ win_perc + field_goal_perc + three_point_perc + free_throw_perc + two_point_perc, i)
}
#for(i in 1:16) {plot(percentage_stats_model_linear_fit_points[[i]])}
percentage_stats_model_linear_fit_points[[1]]$coefficients
coefficient_frame_percentage_stats_points <- data.frame(
percentage_stats_model_linear_fit_points[[1]]$coefficients, percentage_stats_model_linear_fit_points[[2]]$coefficients, percentage_stats_model_linear_fit_points[[3]]$coefficients, percentage_stats_model_linear_fit_points[[4]]$coefficients, percentage_stats_model_linear_fit_points[[5]]$coefficients, percentage_stats_model_linear_fit_points[[6]]$coefficients, percentage_stats_model_linear_fit_points[[7]]$coefficients, percentage_stats_model_linear_fit_points[[8]]$coefficients, percentage_stats_model_linear_fit_points[[9]]$coefficients, percentage_stats_model_linear_fit_points[[10]]$coefficients, percentage_stats_model_linear_fit_points[[11]]$coefficients, percentage_stats_model_linear_fit_points[[12]]$coefficients, percentage_stats_model_linear_fit_points[[13]]$coefficients, percentage_stats_model_linear_fit_points[[14]]$coefficients, percentage_stats_model_linear_fit_points[[15]]$coefficients, percentage_stats_model_linear_fit_points[[16]]$coefficients)
transposeC <- as.data.frame(t(coefficient_frame_percentage_stats_points))
interceptMeanC <- mean(transposeC$`(Intercept)`)
turnoverMeanC <- mean(transposeC$avg_turnovers)
foulsMeanC <- mean(transposeC$avg_fouls)
assistsMeanC <- mean(transposeC$avg_assists)
reboundsMeanC <- mean(transposeC$avg_rebounds)
stealsMeanC <- mean(transposeC$avg_steals)
blocksMeanC <- mean(transposeC$avg_blocks)
blocksAgainstMeanC <- mean(transposeC$avg_blocks_against)
testframeC <- data_copy_for_adding_fold_id 
testframeC %>% mutate(guess = (turnoverMeanA * avg_turnovers) + (foulsMeanA * avg_fouls) + (assistsMeanA * avg_assists) + (reboundsMeanA * avg_rebounds) + (stealsMeanA * avg_steals) + (blocksMeanA * avg_blocks) + (blocksAgainstMeanA * avg_blocks_against) + interceptMeanA, diff = guess - avg_points) %>% ggplot(aes(x = diff)) + geom_histogram()

#cross val of percentage stats for asd
percentage_stats_model_linear_fit_asd <- rep(NULL, 16)
for (i in 1:16){
  percentage_stats_model_linear_fit_asd <- crossValidatorInator(data_copy_for_adding_fold_id, avg_score_differential ~ win_perc + field_goal_perc + three_point_perc + free_throw_perc + two_point_perc, i)
}
percentage_stats_model_linear_fit_asd
head(data_copy_for_adding_fold_id)
#percentage stats
#lasso?
#options from correlation matrix
#all defensive, all offensive, (note we have to mutate the rebound col)

```

```{r}
#cross validation function that returns RMSE
KcrossValidatorInator <- function(df, recipe, nFold = 16) {
  SquaredError <- rep(0, nFold)
  for(foldID in 1:nFold) {
    lm_object <- lm(data = df %>% filter(fold != foldID), formula = as.formula(recipe))
    pred_fold = predict(lm_object, newdata=df %>% filter(fold == foldID))
    SquaredError[foldID] = mean((df[df$fold==foldID, 'avg_points'] - pred_fold) ^ 2)
  }
  return(sqrt(mean(SquaredError)))
}

lesser_known_model_points_error <- KcrossValidatorInator(data_copy_for_adding_fold_id, avg_points ~ avg_turnovers + avg_fouls + avg_assists + avg_rebounds + avg_steals + avg_blocks + avg_blocks_against)
lesser_known_model_points_error
lesser_known_lm_points <- lm(data = data_copy_for_adding_fold_id, avg_points ~ avg_turnovers + avg_fouls + avg_assists + avg_rebounds + avg_steals + avg_blocks + avg_blocks_against)
str(lesser_known_lm_points)
tidy(lesser_known_lm_points)
summary(lesser_known_lm_points)
fit_resid_df <- data.frame(lesser_known_lm_points$fitted.values, lesser_known_lm_points$residuals, data_copy_for_adding_fold_id$avg_points) 

ggplot(data = fit_resid_df, aes(x = lesser_known_lm_points$fitted.values, y = lesser_known_lm_points$residuals)) + geom_hline(yintercept = 0, color = "blue") + geom_point() + theme_bw() + labs(title = "Residual Plot", x = "Fitted Average Points per Game Values", y = "Residuals")
ggplot(data = fit_resid_df, aes(x = lesser_known_lm_points$fitted.values, y = data_copy_for_adding_fold_id$avg_points)) + geom_abline(slope = 1, intercept = 0, color = "red") + geom_point() + theme_bw() + labs(title = "Accuracy of Model", x = "Fitted Values: Average Points per Game", y = "Observed Values: Average Points per Game")
null_model_points <- lm(data = data_copy_for_adding_fold_id, avg_points ~ 1) 
null_model_points
null_model_points_error <- KcrossValidatorInator(data_copy_for_adding_fold_id, avg_points ~ 1)
null_model_points_error

#too obvious, out
percentage_stats_model_points_error <- KcrossValidatorInator(data_copy_for_adding_fold_id, avg_points ~ win_perc + field_goal_perc + free_throw_perc)
percentage_stats_model_points_error
percentage_stats_lm_points <- lm(data = data_copy_for_adding_fold_id, avg_points ~ win_perc + field_goal_perc + free_throw_perc)
percentage_stats_lm_points


offensive_stats_model_points_error <- KcrossValidatorInator(data_copy_for_adding_fold_id, avg_points ~ avg_o_rebounds + avg_assists + avg_turnovers + avg_blocks_against + avg_fouls)
offensive_stats_model_points_error
offensive_stats_model <- lm(data = data_copy_for_adding_fold_id, avg_points ~ avg_o_rebounds + avg_assists + avg_turnovers + avg_blocks_against + avg_fouls)
offensive_stats_model

defensive_stats_model_points_error <- KcrossValidatorInator(data_copy_for_adding_fold_id, avg_points ~ avg_d_rebounds + avg_steals + avg_blocks + avg_fouls)
defensive_stats_model_points_error
defensive_stats_model <- lm(data = data_copy_for_adding_fold_id, avg_points ~ avg_d_rebounds + avg_steals + avg_blocks + avg_fouls)
defensive_stats_model
```


```{r}
tidy(lesser_known_lm_points)
coefficientLabelVector <- c("Average Blocks Against", "Average Blocks", "Average Turnovers", "Average Fouls", "Average Steals", "Average Rebounds", "Average Assists", "Intercept")
coefplotDraft <- coefplot(model = lesser_known_lm_points, title = "Intervals of Error for the Model Coefficients", xlab = "Coefficient Value", ylab = "Coefficient Name", pointSize = 2, color = "blue", intercept = TRUE, sort = "magnitude", decreasing = TRUE, zeroColor = "orange") + theme_bw() #we like it better with intercept in there, we need to fix the error of from and to vectors not having same length
coefplotDraft
knitr, table
```


